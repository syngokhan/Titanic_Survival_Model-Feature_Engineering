{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "muslim-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "consecutive-greece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we do this with the not slice operation, the equality is definitely ensured...\n",
    "\n",
    "def another_replace_with_thresholds(dataframe, col_name , q1=0.25 , q3 = 0.75):\n",
    "    \n",
    "    up_limit, low_limit = outlier_thresholds(dataframe, col_name, q1, q3)\n",
    "    \n",
    "    dataframe[ (dataframe[col_name] < low_limit) ][col_name] = low_limit\n",
    "    dataframe[ (dataframe[col_name] > up_limit)  ][col_name] = up_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "circular-fitness",
   "metadata": {},
   "outputs": [],
   "source": [
    "def titanic():\n",
    "    \n",
    "    dataframe = pd.read_csv(\"/Users/gokhanersoz/Desktop/VBO_Dataset/titanic.csv\")\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "super-cruise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_thresholds(dataframe, col_name , q1 = 0.25 , q3 = 0.75):\n",
    "    \n",
    "    quantile1 = dataframe[col_name].quantile(q1)\n",
    "    quantile3 = dataframe[col_name].quantile(q3)\n",
    "    interquantile = quantile3 - quantile1\n",
    "    up_limit = quantile3 + 1.5*interquantile\n",
    "    low_limit = quantile1 - 1.5*interquantile\n",
    "    \n",
    "    return up_limit,low_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fabulous-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_thresholds(dataframe, col_name , q1=0.25 , q3 = 0.75):\n",
    "    up_limit, low_limit = outlier_thresholds(dataframe, col_name, q1, q3)\n",
    "    dataframe.loc[ (dataframe[col_name] < low_limit) , col_name ] = low_limit\n",
    "    dataframe.loc[ (dataframe[col_name] > up_limit) , col_name] = up_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "viral-involvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_outliers(dataframe, col_name , q1 = 0.25, q3 = 0.75):\n",
    "    \n",
    "    up_limit,low_limit= outlier_thresholds(dataframe, col_name , q1 , q3)\n",
    "    \n",
    "    results = \\\n",
    "    dataframe[ (dataframe[col_name] < low_limit) | (dataframe[col_name] > up_limit)].any(axis = None)\n",
    "    \n",
    "    if results:\n",
    "        \n",
    "        result = \"There are outliers\".title()\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        result = \"There are not outliers\".title()\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "operational-trick",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grap_outliers(dataframe, col_name , q1 = 0.25, q3 = 0.75 , index = False):\n",
    "    \n",
    "    up_limit , low_limit = outlier_thresholds(dataframe, col_name , q1 , q3)\n",
    "    \n",
    "    results = \\\n",
    "    dataframe[ ((dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)) ]\n",
    "    \n",
    "    results_shape = results.shape[0]\n",
    "    \n",
    "    if results_shape > 10:\n",
    "        \n",
    "        print(results.head())\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        print(results)\n",
    "    \n",
    "    if index:\n",
    "        \n",
    "        outliers_index = dataframe[((dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit))].index\n",
    "        outliers_index = outliers_index.tolist()\n",
    "        \n",
    "        return outliers_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "interested-formation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(dataframe, col_name , q1 = 0.25, q3 = 0.75):\n",
    "    \n",
    "    up_limit, low_limit = outlier_thresholds(dataframe, col_name , q1 , q3)\n",
    "    \n",
    "    df_without_outliers = \\\n",
    "    dataframe[ ~((dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit))]\n",
    "    \n",
    "    return df_without_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "academic-mentor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values_table(dataframe, na_name = False):\n",
    "    \n",
    "    # We are check True False\n",
    "    \n",
    "    na_columns = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0] \n",
    "    n_miss = dataframe[na_columns].isnull().sum().sort_values(ascending = False)\n",
    "    ratio = (dataframe[na_columns].isnull().sum() / dataframe.shape[0] * 100).sort_values(ascending = False)\n",
    "    \n",
    "    # for columns's name we need to add keys ...\n",
    "    \n",
    "    missing_df = pd.concat([n_miss, np.round(ratio, 3)], axis = 1 , keys = [\"n_miss\", \"ratio\"] )\n",
    "    \n",
    "    print(missing_df,end = \"\\n\\n\")\n",
    "    \n",
    "    if na_name:\n",
    "        return na_columns\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "verified-capability",
   "metadata": {},
   "outputs": [],
   "source": [
    "def another_missing_values_table(dataframe, na_name = False):\n",
    "    # We are check True False\n",
    "    \n",
    "    na_columns = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0] \n",
    "    n_miss = dataframe[na_columns].isnull().sum().sort_values(ascending = False)\n",
    "    n_miss = pd.DataFrame(n_miss, columns = [\"N_Miss\"])\n",
    "    ratio = (dataframe[na_columns].isnull().sum() / dataframe.shape[0] * 100).sort_values(ascending = False)\n",
    "    ratio = pd.DataFrame(ratio, columns = [\"Ratio\"])\n",
    "    \n",
    "    # for columns's name we need to add keys ...\n",
    "    \n",
    "    missing_df = pd.concat([n_miss, np.round(ratio, 3)], axis = 1 )\n",
    "    \n",
    "    if na_name:\n",
    "        return na_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "conscious-vacuum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_vs_target(dataframe, target , na_columns ):\n",
    "    \n",
    "    # df[\"Age_Flag\"] = np.where(df[\"Age\"].isnull() , 1, 0)\n",
    "    # df[(df[\"Age\"].isnull())].groupby([\"Age_Flag\"])[\"Survived\"].count() / df[(df[\"Age\"].isnull())] .shape[0]\n",
    "    # We are already reducing the empty values to 2 variables by making 1 and 0, and accordingly according to the target variable\n",
    "    # We continue to trade...\n",
    "    \n",
    "    \"\"\"\n",
    "    We need to use missing_values_table(dataframe, na_name = True)....\n",
    "    \n",
    "    1 if missing value 0 if not missing value....\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    temp_df = dataframe.copy()\n",
    "    \n",
    "    for col in na_columns:\n",
    "        temp_df[col + \"_NA_FLAG\"] = np.where(temp_df[col].isnull(), 1, 0)\n",
    "    \n",
    "    na_flags = temp_df.loc[:,temp_df.columns.str.contains(\"_NA_\")].columns\n",
    "    \n",
    "    for col in na_flags:\n",
    "        print(pd.DataFrame({\"TARGET_MEAN\" : temp_df.groupby(col)[target].mean(),\n",
    "                      \"Count\" : temp_df.groupby(col)[target].count()}), end = \"\\n\\n\" )\n",
    "        \n",
    "    #return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acting-mainstream",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoder(dataframe, binary_col):\n",
    "    labelencoder = LabelEncoder()\n",
    "    dataframe[binary_col] = labelencoder.fit_transform(dataframe[binary_col])\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "radio-brooklyn",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(dataframe , categorical_cols , drop_first=False):\n",
    "    dataframe = pd.get_dummies(dataframe,columns = categorical_cols, drop_first=drop_first)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fitted-redhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rare_analyser(dataframe, target, cat_cols):\n",
    "    \n",
    "    #test = pd.DataFrame({\"Age\" : [1,1,1,3,3,3,4,4,4,5,5,5,5,5,6,7,7,7,7],\n",
    "    #####                 \"Survived\" :   [1,0,1,1,0,1,1,1,0,0,0,0,1,1,1,1,0,0,0]})\n",
    "    #test.groupby(\"Age\")[\"Survived\"].count()\n",
    "    #test.groupby(\"Age\")[\"Survived\"].mean()\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Need cat_cols\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    for col in cat_cols:\n",
    "        print(\"FOR\" , col.upper(), \":\", len(dataframe[col].value_counts()),end = \"\\n\\n\")\n",
    "        #print(col, \":\", dataframe[col].nunique())\n",
    "        print(pd.DataFrame({\"COUNT\" : dataframe[col].value_counts(),\n",
    "                            \"RATIO\" : dataframe[col].value_counts() / len(dataframe), \n",
    "                            \"TARGET_MEAN\" : dataframe.groupby(col)[target].mean()}), end = \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "progressive-investigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rare_encoder(dataframe, rare_perc):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Object ones are determined.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    temp_df = dataframe.copy()\n",
    "    \n",
    "    rare_columns = [col for col in temp_df.columns if temp_df[col].dtype == \"object\" and \\\n",
    "                    (temp_df[col].value_counts() / len(temp_df) < rare_perc).any(axis = None)]\n",
    "    \n",
    "    for var in rare_columns:\n",
    "        \n",
    "        tmp = temp_df[var].value_counts() / len(temp_df)\n",
    "        rare_labels = tmp[tmp < rare_perc].index\n",
    "        temp_df[var] = np.where(temp_df[var].isin(rare_labels), \"Rare\", temp_df[var])\n",
    "        \n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-amount",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-hormone",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-honduras",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-following",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
